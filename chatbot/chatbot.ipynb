{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PRt0Gnw7IdER"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai SpeechRecognition pyttsx3 pyaudio keyboard googletrans==4.0.0-rc1 gTTS playsound pygame --timeout 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2QGNRrp-YhJt"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDnJCqBXoFMwmiI_mzGY98SecoSqYcBV8s\"\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================--------------------------\n",
      "Model Name: models/embedding-gecko-001, \n",
      " Description: Obtain a distributed representation of a text.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-flash, \n",
      " Description: Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-pro, \n",
      " Description: Stable release (June 17th, 2025) of Gemini 2.5 Pro\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-exp, \n",
      " Description: Gemini 2.0 Flash Experimental\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash, \n",
      " Description: Gemini 2.0 Flash\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-001, \n",
      " Description: Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-exp-image-generation, \n",
      " Description: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-lite-001, \n",
      " Description: Stable version of Gemini 2.0 Flash-Lite\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-lite, \n",
      " Description: Gemini 2.0 Flash-Lite\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-lite-preview-02-05, \n",
      " Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-lite-preview, \n",
      " Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-exp-1206, \n",
      " Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-flash-preview-tts, \n",
      " Description: Gemini 2.5 Flash Preview TTS\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-pro-preview-tts, \n",
      " Description: Gemini 2.5 Pro Preview TTS\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemma-3-1b-it, \n",
      " Description: \n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemma-3-4b-it, \n",
      " Description: \n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemma-3-12b-it, \n",
      " Description: \n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemma-3-27b-it, \n",
      " Description: \n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemma-3n-e4b-it, \n",
      " Description: \n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemma-3n-e2b-it, \n",
      " Description: \n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-flash-latest, \n",
      " Description: Latest release of Gemini Flash\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-flash-lite-latest, \n",
      " Description: Latest release of Gemini Flash-Lite\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-pro-latest, \n",
      " Description: Latest release of Gemini Pro\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-flash-lite, \n",
      " Description: Stable version of Gemini 2.5 Flash-Lite, released in July of 2025\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-flash-image-preview, \n",
      " Description: Gemini 2.5 Flash Preview Image\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-flash-image, \n",
      " Description: Gemini 2.5 Flash Preview Image\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-flash-preview-09-2025, \n",
      " Description: Gemini 2.5 Flash Preview Sep 2025\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-flash-lite-preview-09-2025, \n",
      " Description: Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-3-pro-preview, \n",
      " Description: Gemini 3 Pro Preview\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-3-flash-preview, \n",
      " Description: Gemini 3 Flash Preview\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-3-pro-image-preview, \n",
      " Description: Gemini 3 Pro Image Preview\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/nano-banana-pro-preview, \n",
      " Description: Gemini 3 Pro Image Preview\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-robotics-er-1.5-preview, \n",
      " Description: Gemini Robotics-ER 1.5 Preview\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-computer-use-preview-10-2025, \n",
      " Description: Gemini 2.5 Computer Use Preview 10-2025\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/deep-research-pro-preview-12-2025, \n",
      " Description: Preview release (December 12th, 2025) of Deep Research Pro\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/embedding-001, \n",
      " Description: Obtain a distributed representation of a text.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/text-embedding-004, \n",
      " Description: Obtain a distributed representation of a text.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-embedding-exp-03-07, \n",
      " Description: Obtain a distributed representation of a text.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-embedding-exp, \n",
      " Description: Obtain a distributed representation of a text.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-embedding-001, \n",
      " Description: Obtain a distributed representation of a text.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/aqa, \n",
      " Description: Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/imagen-4.0-generate-preview-06-06, \n",
      " Description: Vertex served Imagen 4.0 model\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/imagen-4.0-ultra-generate-preview-06-06, \n",
      " Description: Vertex served Imagen 4.0 ultra model\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/imagen-4.0-generate-001, \n",
      " Description: Vertex served Imagen 4.0 model\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/imagen-4.0-ultra-generate-001, \n",
      " Description: Vertex served Imagen 4.0 ultra model\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/imagen-4.0-fast-generate-001, \n",
      " Description: Vertex served Imagen 4.0 Fast model\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/veo-2.0-generate-001, \n",
      " Description: Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/veo-3.0-generate-001, \n",
      " Description: Veo 3\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/veo-3.0-fast-generate-001, \n",
      " Description: Veo 3 fast\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/veo-3.1-generate-preview, \n",
      " Description: Veo 3.1\n",
      "====================================================--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================--------------------------\n",
      "Model Name: models/veo-3.1-fast-generate-preview, \n",
      " Description: Veo 3.1 fast\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-flash-native-audio-latest, \n",
      " Description: Latest release of Gemini 2.5 Flash Native Audio\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-flash-native-audio-preview-09-2025, \n",
      " Description: Gemini 2.5 Flash Native Audio Preview 09-2025\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-flash-native-audio-preview-12-2025, \n",
      " Description: Gemini 2.5 Flash Native Audio Preview 12-2025\n",
      "====================================================--------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to list available models\n",
    "def list_available_models():\n",
    "    models = genai.list_models()\n",
    "    for model in models:\n",
    "        print(\"====================================================--------------------------\")\n",
    "        print(f\"Model Name: {model.name}, \\n Description: {getattr(model, 'description', 'No description available')}\")\n",
    "        print(\"====================================================--------------------------\")\n",
    "\n",
    "# Call the function to list models\n",
    "list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = genai.GenerativeModel(\"models/gemini-2.0-flash-lite-001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Where to cultivate wheat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-lite\nPlease retry in 32.656539785s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash-lite\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash-lite\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash-lite\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 32\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mgenerate_content(prompt)\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    332\u001b[0m             request,\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m    836\u001b[0m     request,\n\u001b[0;32m    837\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m    838\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    839\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    840\u001b[0m )\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[0;32m    154\u001b[0m         exc,\n\u001b[0;32m    155\u001b[0m         deadline,\n\u001b[0;32m    156\u001b[0m         sleep,\n\u001b[0;32m    157\u001b[0m         error_list,\n\u001b[0;32m    158\u001b[0m         predicate,\n\u001b[0;32m    159\u001b[0m         on_error,\n\u001b[0;32m    160\u001b[0m         exception_factory,\n\u001b[0;32m    161\u001b[0m         timeout,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-lite\nPlease retry in 32.656539785s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash-lite\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash-lite\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash-lite\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 32\n}\n]"
     ]
    }
   ],
   "source": [
    "model.generate_content(prompt).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_prompt(prompt):\n",
    "    return f\"You are AgriBot, an agriculture assistant. Answer this question\\n{prompt}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "# Supported language codes\n",
    "lang_codes = {\n",
    "    \"english\": \"en\",\n",
    "    \"urdu\": \"ur\"\n",
    "}\n",
    "\n",
    "conversation_history = []\n",
    "MAX_TURNS = 5\n",
    "selected_lang = \"en\"\n",
    "\n",
    "# Language choice\n",
    "def choose_language():\n",
    "    global selected_lang\n",
    "    print(\"ðŸŒ Choose your language: English, Urdu\")\n",
    "    lang = input(\"Language: \").strip().lower()\n",
    "    selected_lang = lang_codes.get(lang, \"en\")\n",
    "    print(f\"âœ… Language set to: {lang.title()}\")\n",
    "\n",
    "# Translate input to English (if needed)\n",
    "def translate_to_english(text):\n",
    "    if selected_lang == \"en\":\n",
    "        return text\n",
    "    else:\n",
    "        return translator.translate(text, src=selected_lang, dest=\"en\").text\n",
    "\n",
    "# Translate English response to selected language\n",
    "def translate_from_english(text):\n",
    "    if selected_lang == \"en\":\n",
    "        return text\n",
    "    else:\n",
    "        return translator.translate(text, src=\"en\", dest=selected_lang).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = []  # Store conversation\n",
    "\n",
    "MAX_TURNS = 5  # Max turns to keep for context\n",
    "\n",
    "def format_conversation(history, prompt, limit=MAX_TURNS):\n",
    "    history_text = \"\"\n",
    "    # Only keep last `limit` turns to keep token usage low\n",
    "    for turn in history[-limit:]:\n",
    "        history_text += f\"User: {turn['user']}\\nBot: {turn['bot']}\\n\"\n",
    "    history_text += f\"User: {prompt}\\nBot:\"\n",
    "    return f\"You are AgriBot, an agriculture assistant. Answer this question:\\n{history_text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask model: Is it agriculture-related?\n",
    "#def is_agriculture_related(prompt):\n",
    " #   classification_prompt = f\"Is the following question related to agriculture? Reply only 'Yes' or 'No'.\\nQuestion: {prompt}\"\n",
    "  #  result = model.generate_content(classification_prompt).text.strip().lower()\n",
    "   # return result.startswith(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate content\n",
    "def generate_contet(prompt):\n",
    "    full_prompt = format_conversation(conversation_history, prompt)\n",
    "    response = model.generate_content(full_prompt)\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsDbSeP8y7Ld"
   },
   "source": [
    "### Voice integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_input():\n",
    "    return input(\"ðŸ‘¤ You:\\n >>> \")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voice_input():\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone()\n",
    "    \n",
    "    # Google speech recognition language code according to selected_lang\n",
    "    lang_code = \"en-US\" if selected_lang == \"en\" else \"ur-PK\"\n",
    "\n",
    "    try:\n",
    "        with mic as source:\n",
    "            print(\"ðŸŽ¤ Speak now...\")\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            audio = recognizer.listen(source, timeout=10)\n",
    "        # Detect voice in selected language\n",
    "        text = recognizer.recognize_google(audio, language=lang_code)\n",
    "        print(f\"ðŸ—£ï¸ You said: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"âŒ Could not understand voice. Switching to text input.\")\n",
    "        return text_input()\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"âŒ API Error: {e}\")\n",
    "        return text_input()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import time\n",
    "import os\n",
    "import uuid\n",
    "from gtts import gTTS\n",
    "\n",
    "def speak_output(text):\n",
    "    try:\n",
    "        tts_lang = \"en\" if selected_lang == \"en\" else \"ur\"\n",
    "        tts = gTTS(text=text, lang=tts_lang)\n",
    "        filename = f\"temp_{uuid.uuid4()}.mp3\"\n",
    "        tts.save(filename)\n",
    "\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load(filename)\n",
    "        pygame.mixer.music.play()\n",
    "\n",
    "        # Wait for the audio to finish playing\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            time.sleep(0.1)\n",
    "\n",
    "        # Stop the mixer properly before deleting the file\n",
    "        pygame.mixer.music.stop()\n",
    "        pygame.mixer.quit()  # âœ… important\n",
    "\n",
    "        time.sleep(0.1)  # slight delay to ensure file is released\n",
    "        os.remove(filename)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Voice output failed: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ Choose your language: English, Urdu\n",
      "Language: urdu\n",
      "âœ… Language set to: Urdu\n",
      "ðŸ§  Do you want to use Voice or Text mode? (v/t): v\n",
      "ðŸ’¬ Say 'exit','bye' or 'quiet' to stop.\n",
      "\n",
      " Ú†ÛŒÙ¹ Ø¨Ù†Ø¯ Ú©Ø±Ù†Û’ Ú©Û’Ù„ÛŒÛ’ 'Ø§Ù„ÙˆØ¯Ø§Ø¹', 'Ø®Ø¯Ø§ Ø­Ø§ÙØ¸' ÛŒØ§ 'Ø¨Ù†Ø¯ Ú©Ø±Ùˆ' Ù¾Ú‘Ú¾ÛŒÚº ÛŒØ§ Ø¯Ø§Ø¦ÛŒÚº\n",
      "ðŸŽ¤ Speak now...\n",
      "ðŸ—£ï¸ You said: Ú©Ù¾Ø§Ø³ Ú©Û’ ÙØµÙ„ Ú©Ùˆ Ú©ÛŒØ³Û’ Ø¨ÛØªØ± Ø¨Ù†Ø§ÛŒØ§ Ø¬Ø§Ø¦Û’\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m             conversation_history\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Start chat\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m chat_with_user()\n",
      "Cell \u001b[1;32mIn[35], line 39\u001b[0m, in \u001b[0;36mchat_with_user\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;66;03m# Check if it's agriculture-related\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#        if is_agriculture_related(translated_input):\u001b[39;00m\n\u001b[0;32m     30\u001b[0m         english_response \u001b[38;5;241m=\u001b[39m generate_contet(translated_input)\n\u001b[1;32m---> 39\u001b[0m         final_response \u001b[38;5;241m=\u001b[39m translate_from_english(english_response)\n\u001b[0;32m     40\u001b[0m  \u001b[38;5;66;03m#       else:\u001b[39;00m\n\u001b[0;32m     41\u001b[0m   \u001b[38;5;66;03m#          if selected_lang == \"ur\":\u001b[39;00m\n\u001b[0;32m     42\u001b[0m    \u001b[38;5;66;03m#             final_response = \"ðŸ™ Ù…ÛŒÚº ØµØ±Ù Ø²Ø±Ø§Ø¹Øª Ø³Û’ Ù…ØªØ¹Ù„Ù‚ Ø³ÙˆØ§Ù„Ø§Øª Ú©Û’ Ø¬ÙˆØ§Ø¨Ø§Øª Ø¯Û’ Ø³Ú©ØªØ§ ÛÙˆÚºÛ” Ø¨Ø±Ø§Û Ú©Ø±Ù… ÙØµÙ„ÙˆÚº ÛŒØ§ Ú©Ú¾ÛŒØªÛŒ Ø¨Ø§Ú‘ÛŒ Ø³Û’ Ù…ØªØ¹Ù„Ù‚ Ø³ÙˆØ§Ù„ Ù¾ÙˆÚ†Ú¾ÛŒÚºÛ”\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m#        else:\u001b[39;00m\n\u001b[0;32m     44\u001b[0m      \u001b[38;5;66;03m#           final_response = \"ðŸ™ I can only answer agriculture-related questions. Please ask me something about farming or crops.\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ¤– Agribot:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, final_response)\n",
      "Cell \u001b[1;32mIn[27], line 35\u001b[0m, in \u001b[0;36mtranslate_from_english\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m translator\u001b[38;5;241m.\u001b[39mtranslate(text, src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m, dest\u001b[38;5;241m=\u001b[39mselected_lang)\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\googletrans\\client.py:219\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[1;34m(self, text, dest, src)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    218\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(resp)\n\u001b[1;32m--> 219\u001b[0m parsed \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# not sure\u001b[39;00m\n\u001b[0;32m    221\u001b[0m should_spacing \u001b[38;5;241m=\u001b[39m parsed[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[1;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[1;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not NoneType"
     ]
    }
   ],
   "source": [
    "\n",
    "exit_keywords = {\n",
    "    \"en\": [\"exit\", \"bye\", \"quit\"],\n",
    "    \"ur\": [\"Ø§Ù„ÙˆØ¯Ø§Ø¹\", \"Ø®Ø¯Ø§ Ø­Ø§ÙØ¸\", \"Ú†Ù„ÛŒÚº\", \"Ø®Ø¯Ø§\", \"Ø±Ø®ØµØª\", \"Ø¨Ù†Ø¯ Ú©Ø±Ùˆ\"]\n",
    "}\n",
    "\n",
    "def chat_with_user():\n",
    "    choose_language()  # Set language at start\n",
    "    mode = input(\"ðŸ§  Do you want to use Voice or Text mode? (v/t): \").strip().lower()\n",
    "    print(\"ðŸ’¬ Say 'exit','bye' or 'quiet' to stop.\\n\")\n",
    "    print(\" Ú†ÛŒÙ¹ Ø¨Ù†Ø¯ Ú©Ø±Ù†Û’ Ú©Û’Ù„ÛŒÛ’ 'Ø§Ù„ÙˆØ¯Ø§Ø¹', 'Ø®Ø¯Ø§ Ø­Ø§ÙØ¸' ÛŒØ§ 'Ø¨Ù†Ø¯ Ú©Ø±Ùˆ' Ù¾Ú‘Ú¾ÛŒÚº ÛŒØ§ Ø¯Ø§Ø¦ÛŒÚº\")\n",
    "\n",
    "    while True:\n",
    "        if mode == 'v':\n",
    "            prompt = voice_input()\n",
    "        else:\n",
    "            prompt = text_input()\n",
    "\n",
    "        # Check if user wants to exit\n",
    "        if prompt.strip().lower() in exit_keywords[selected_lang]:\n",
    "            if selected_lang == \"ur\":\n",
    "                print(\"ðŸ‘‹ !Ú†ÛŒÙ¹ Ø¨Ù†Ø¯ Ú©ÛŒ Ø¬Ø§ Ø±ÛÛŒ ÛÛ’Û” Ø§Ù„Ù„Û Ø­Ø§ÙØ¸\")\n",
    "            else:\n",
    "                print(\"ðŸ‘‹ Exiting chat. Have a good day!\")\n",
    "            break\n",
    "\n",
    "        # Continue processing\n",
    "        translated_input = translate_to_english(prompt)\n",
    "        # Check if it's agriculture-related\n",
    "#        if is_agriculture_related(translated_input):\n",
    "        english_response = generate_contet(translated_input)\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        final_response = translate_from_english(english_response)\n",
    " #       else:\n",
    "  #          if selected_lang == \"ur\":\n",
    "   #             final_response = \"ðŸ™ Ù…ÛŒÚº ØµØ±Ù Ø²Ø±Ø§Ø¹Øª Ø³Û’ Ù…ØªØ¹Ù„Ù‚ Ø³ÙˆØ§Ù„Ø§Øª Ú©Û’ Ø¬ÙˆØ§Ø¨Ø§Øª Ø¯Û’ Ø³Ú©ØªØ§ ÛÙˆÚºÛ” Ø¨Ø±Ø§Û Ú©Ø±Ù… ÙØµÙ„ÙˆÚº ÛŒØ§ Ú©Ú¾ÛŒØªÛŒ Ø¨Ø§Ú‘ÛŒ Ø³Û’ Ù…ØªØ¹Ù„Ù‚ Ø³ÙˆØ§Ù„ Ù¾ÙˆÚ†Ú¾ÛŒÚºÛ”\"\n",
    "    #        else:\n",
    "     #           final_response = \"ðŸ™ I can only answer agriculture-related questions. Please ask me something about farming or crops.\"\n",
    "   \n",
    "    \n",
    "        print(\"\\n\\nðŸ¤– Agribot:\\n\", final_response)\n",
    "\n",
    "        if mode == 'v':\n",
    "            speak_output(final_response)\n",
    "\n",
    "        # Save the exchange to history\n",
    "        conversation_history.append({\"user\": prompt, \"bot\": final_response})\n",
    "        if len(conversation_history) > MAX_TURNS:\n",
    "            conversation_history.pop(0)\n",
    "\n",
    "# Start chat\n",
    "chat_with_user()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
